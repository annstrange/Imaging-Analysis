{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776f14dc",
   "metadata": {},
   "source": [
    "# Measure CellPose ROIs to FCS\n",
    "\n",
    "Likely can be used for other ROI sources, but need:  \n",
    "1. folder and filename pattern containing component images. \n",
    "2. folder and filename pattern containing cell segmentation masks.\n",
    "3. output folder and filename for csv and FCS file of measuress. \n",
    "\n",
    "Todo:  \n",
    "1. Take tissue segmentation into account.\n",
    "2. consider running pixie or CellSeg (Stanford pipeline) \n",
    "3. adapt for higher resoultion images\n",
    "\n",
    "What this does:  \n",
    "1. Reads in masks and component image files\n",
    "2. Normalization of compononent images to let the intensities be on the same scale.\n",
    "3. use scikit-image.measure to collect measures of interest at cell and nuclear level? My masks are at entire-cell level. \n",
    "4. Prepares files in ark-analysis folder & naming conventions to get total intensities, normalized\n",
    "\n",
    "\n",
    "Depends on:  \n",
    "Run Format_Polaris_for_ark notebook before this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc00e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tifffile as tif\n",
    "import fnmatch\n",
    "import re\n",
    "\n",
    "from skimage import io, color, filters, exposure\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline \n",
    "\n",
    "# ROI measures\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "\n",
    "import xarray as xr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddacc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flowkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include measurement code from ark-analysis\n",
    "import marker_quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowkit as fk\n",
    "from bokeh.io import output_notebook, show\n",
    "#%bokeh inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae92c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "# Set file paths\n",
    "root_dir = '/Users/annmstrange/Documents/Projects/Tumor IF'\n",
    "\n",
    "components_dir= os.path.join(root_dir, \"Panel2/Export P28 21 full40x\")\n",
    "#components_dir = os.path.join(root_dir, \"Panel2/Export P28 full40x\")  \n",
    "#components_dir = os.path.join(root_dir, \"Panel3/Export P68 full40x\")\n",
    "\n",
    "#mask_img_path='Panel2/CellPose_moreCyto/Masks'\n",
    "masks_dir = os.path.join(root_dir, \"Panel2/CellPose40x_21/Masks\")\n",
    "#masks_dir = os.path.join(root_dir, \"Panel2/CellPose40x_23/Masks\")\n",
    "#masks_dir = os.path.join(root_dir, \"Panel3/CellPose40x_23/Masks\")\n",
    "\n",
    "tifs_dir=os.path.join(root_dir, 'Panel2/ark-analysis_21')\n",
    "#tifs_dir=os.path.join(root_dir, 'Panel2/ark-analysis_23')\n",
    "#tifs_dir=os.path.join(root_dir, 'Panel3/ark-analysis_23')\n",
    "\n",
    "\n",
    "fcs_path=os.path.join(root_dir,'Panel3/FCS')\n",
    "output_path_P28_21 = os.path.join(root_dir,'Panel2/output_21')\n",
    "output_path_P28_23 = os.path.join(root_dir,'Panel2/output_23')\n",
    "output_path_P68 = os.path.join(root_dir,'Panel3/output_23')\n",
    "\n",
    "channels_p28 = ['CD3','pSTAT3 Y705', 'CD4', 'pSTAT5','pSTAT3 S727','pSTAT1', 'SOX10S100', 'CD8','DAPI','Autofluorescence']\n",
    "# Opal 480, 520, 540, 570, 620, 650, 690, 780, DAPI\n",
    "channels_p68 = ['pSTAT6','SOX10S100','pSTAT4', 'CD4','CD3',\n",
    "                'pSTAT1 S727', 'pSTAT2', 'CD8','DAPI','Autofluorescence']\n",
    "\n",
    "#channels = ['CD3','Ki67', 'CD4', 'SOX10S100', 'CD39','CD83','CD38', 'CD8','DAPI','Autofluorescence']\n",
    "opals = ['Opal 480', 'Opal 520', 'Opal 540', 'Opal 570', 'Opal 620','Opal 650','Opal 690', 'Opal 780', 'DAPI', '']\n",
    "\n",
    "output_path = output_path_P28_21\n",
    "channels=channels_p28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef890b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder (src, pattern):\n",
    "    '''\n",
    "    Args: src is the full path where to look recursively\n",
    "    pattern: string like '*_pattern.tif' to use with fnmatch.filter\n",
    "    Returns: list of full filenames\n",
    "    '''\n",
    "    # build list of filenames we want\n",
    "    fname_list = []\n",
    "\n",
    "    for dirpath, dir, files in os.walk(src):\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "            fname = filename\n",
    "            fullname = os.path.join(dirpath, filename)\n",
    "            fname_list.append(fullname)\n",
    "            \n",
    "    return sorted(fname_list) \n",
    "\n",
    " \n",
    "fname_component = get_files_in_folder(components_dir, '*_component_data.tif') \n",
    "\n",
    "print('found {0} files matching the pattern'.format(len(fname_component)))\n",
    "print(fname_component[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for normalization\n",
    "def get_max_intensities_by_channel (filename_list):\n",
    "    '''\n",
    "    Arguments: filename_list is list of component files\n",
    "    Returns: array of length 10 with the max intensity in each channel\n",
    "    '''\n",
    "\n",
    "    tally_arr = np.zeros(10)\n",
    "    #print(tally_arr.shape)\n",
    "    for file in filename_list:\n",
    "        img_arr = io.imread(file)\n",
    "        max_values = np.max(np.max(img_arr, axis=2),axis=1)\n",
    "        #print(max_values)\n",
    "        #print(max_values.shape)\n",
    "        tally_arr = np.max([tally_arr, max_values], axis = 0)\n",
    "        #print(tally_arr)\n",
    "        \n",
    "    return tally_arr\n",
    "\n",
    "print(\"checking {} images in list\".format(len(fname_component)))\n",
    "max_intensities = get_max_intensities_by_channel(fname_component)\n",
    "print(max_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a component from our data\n",
    "fname_masks = get_files_in_folder(masks_dir, 'MASK*_rgb.tif') \n",
    "mask_file1 = fname_masks[0]\n",
    "mask_file1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component files for intensity\n",
    "# get a component from our data\n",
    "fname_components = get_files_in_folder (components_dir, '*_component_data.tif') \n",
    "component_file1 = fname_components[0]\n",
    "component_file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better to make sure the filenames exactly match up. \n",
    "# with a mask file, convert filename\n",
    "\n",
    "comp_file = mask_file1.replace(\"MASK_\", \"\").replace(\"_rgb\", \"_component_data\").replace(masks_dir, components_dir)\n",
    "print(comp_file)\n",
    "\n",
    "os.path.exists(comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For normalization of each channel's intensity, get max intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Need X Position, Y Position from centroid tuple 0 and 1 (Y and X)\n",
    "#.     column rename centroid-0 to Y Position. centroid-1 to X Position\n",
    "# Do I want nuclear vs whole cell? labels to start with 'Entire Cell' to match InForm\n",
    "# intensity_max, stdev? \n",
    "\n",
    "# columns phenoptr spatial probably wants _____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test xarray is working\n",
    "\n",
    "# data = xr.DataArray(np.random.randn(2, 3), dims=(\"x\", \"y\"), coords={\"x\": [10, 20]})\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaa739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get same stats as ark-analysis:\n",
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "\n",
    "#fldr = 'Panel2/ark-analysis/091221 P9HuP28 #10 S16-003395 A1_[13463,50983]'\n",
    "#tiff_dir = 'Panel2/ark-analysis'\n",
    "sample1 = '091221 P9HuP28 #10 S16-003395 A1_[19347,49169]'\n",
    "#mask_dir = os.path.join(root_dir,'Panel2/ark-analysis_21', sample1) # /091221 P9HuP28 #14 S15-014984 A4_[17537,46960]'\n",
    "#mask_dir = os.path.join(masks_dir, sample1)\n",
    "# expect mask fldr to have 2 files ending with _feature_0.tif and _feature_1.tif\n",
    "\n",
    "\n",
    "\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_dir=os.path.join(tifs_dir, sample1),\n",
    "                                              tiff_dir=tifs_dir,\n",
    "                                              img_sub_folder=\"TIFs\",\n",
    "                                              is_mibitiff=False,\n",
    "                                              # this subfolder is looked in for TIFs\n",
    "                                              fovs=[sample1],\n",
    "                                              batch_size=1\n",
    "                                              )\n",
    "\n",
    "                                              #nuclear_counts=nuclear_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_table_size_normalized['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in function\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    \n",
    "#fldr = 'Panel2/ark-analysis/091221 P9HuP28 #10 S16-003395 A1_[13463,50983]'\n",
    "#tiff_dir = os.path.join(root_dir,'Panel2/ark-analysis_21')\n",
    "sample1 = '091221 P9HuP28 #10 S16-003395 A1_[19347,49169]'\n",
    "#mask_dir = 'Panel2/ark-analysis_21/091221 P9HuP28 #10 S16-003395 A1_[19347,49169]'\n",
    "#mask_dir = os.path.join(root_dir,'Panel2/ark-analysis_21', sample1)\n",
    "# expect mask fldr to have 2 files ending with _feature_0.tif and _feature_1.tif\n",
    "\n",
    "\n",
    "def get_total_intensities(mask_dir, component_dir, roi_name):\n",
    "    '''\n",
    "    Arguments:\n",
    "        mask_dir is path to mask file\n",
    "        component_dir is path to where a 10 channel component image is\n",
    "    '''\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "        warnings.filterwarnings(\"ignore\", \n",
    "                                message=\"The frame.append method is deprecated\")\n",
    "        # and will be removed from pandas in a future version. Use pandas.concat instead.\")\n",
    "    print(mask_dir, component_dir)    \n",
    "    \n",
    "    cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "        marker_quantification.generate_cell_table(segmentation_dir=mask_dir,\n",
    "                                                  tiff_dir=component_dir,\n",
    "                                                  img_sub_folder=\"TIFs\",\n",
    "                                                  is_mibitiff=False,\n",
    "                                                  # this subfolder is looked in for TIFs\n",
    "                                                  fovs=[roi_name],\n",
    "                                                  batch_size=1\n",
    "                                                  )\n",
    "        \n",
    "    return (cell_table_size_normalized)\n",
    "\n",
    "\n",
    "\n",
    "cell_table_size_norm = get_total_intensities(os.path.join(tifs_dir, sample1),\n",
    "                                             tifs_dir, sample1)\n",
    "cell_table_size_norm.reset_index(inplace=True)\n",
    "cell_table_size_norm.rename({'index': 'cell_id'}, axis=\"columns\", inplace=True)\n",
    "cell_table_size_norm.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fe766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate sample rois\n",
    "df_samples = pd.DataFrame(enumerate (sorted(os.listdir(tifs_dir))))\n",
    "df_samples.columns = ['index', 'sample_nm']\n",
    "print(len(df_samples))\n",
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample_nm index\n",
    "\n",
    "#df_cells2 = cell_table_size_norm.join(df_samples, how=\"inner\", on=['fov', 'sample_nm'])\n",
    "#print(len(df_cells2))\n",
    "\n",
    "sample_idx = df_samples[df_samples['sample_nm']=='091221 P9HuP28 #13 S15-18369 A2_[14965,56532]']\n",
    "sample_idx = df_samples[df_samples['sample_nm']=='091221 P9HuP28 #10 S16-003395 A1_[19347,49169]']\n",
    "sample_idx.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e88e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_cell_id(idx, cell_id):\n",
    "    new_id = str(idx) + \".\" + str(cell_id)\n",
    "    return (float(new_id))\n",
    "\n",
    "make_unique_cell_id(2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e7a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c11233",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813639dc",
   "metadata": {},
   "source": [
    "## ark-analysis measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop subfolders of ark-analysis\n",
    "#mask_dir = os.path.join(root_dir, 'Panel2/ark-analysis_21')\n",
    "#tiff_dir = os.path.join(root_dir, 'Panel2/ark-analysis_21')\n",
    "\n",
    "\n",
    "# del full_cell_table\n",
    "#gc.collect()\n",
    "isFirst=True\n",
    "\n",
    "for i, sample_nm in enumerate(sorted(os.listdir(tifs_dir))):\n",
    "    print(sample_nm)\n",
    "    if (os.path.isdir(os.path.join(tifs_dir, sample_nm))):\n",
    "        print(\"getting ark metrics for {}\".format(sample_nm))\n",
    "        print (i)\n",
    "        cell_table_size_norm = get_total_intensities(os.path.join(tifs_dir, sample_nm),\n",
    "                                                     tifs_dir, \n",
    "                                                     sample_nm)\n",
    "\n",
    "        if (len(cell_table_size_norm) == 0):\n",
    "            continue\n",
    "            \n",
    "        # helpful columns\n",
    "        cell_table_size_norm.reset_index(inplace=True)\n",
    "        cell_table_size_norm['label'] =  cell_table_size_norm['label'].astype(int) \n",
    "        #cell_table_size_norm.rename({'index': 'cell_id'}, axis=\"columns\", inplace=True)\n",
    "        sample_idx = df_samples[df_samples['sample_nm']==sample_nm].iloc[0,0]\n",
    "        print(\"processing sample idx {}\".format(sample_idx))\n",
    "        #sample_idx.iloc[0,0]\n",
    "        cell_table_size_norm['sample_idx'] = sample_idx\n",
    "        cell_table_size_norm['unique_cell_id'] = cell_table_size_norm.apply(\n",
    "            lambda row: float(str(sample_idx) + \".\" + (\"0000\" + str(row.label))[-5:]), axis=1)\n",
    "        if (isFirst):\n",
    "            full_cell_table = cell_table_size_norm\n",
    "            isFirst=False\n",
    "        else:\n",
    "            full_cell_table = pd.concat([full_cell_table, cell_table_size_norm], axis=0)     \n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed444f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_table_size_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cell_table.to_csv(os.path.join(output_path, 'ark-measures.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d281e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_cell_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a12c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary by sample\n",
    "full_cell_table.groupby('fov')['unique_cell_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any non-unique keys?\n",
    "df_check_unique = full_cell_table.groupby('fov')['unique_cell_id'].value_counts()\n",
    "df_check_unique[df_check_unique > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0091221 P9HuP28 #13 S15-18369 A2_[14965,56532]\n",
    "# idx 166\n",
    "# ValueError: Cannot set a DataFrame with multiple columns to the single column unique_cell_id\n",
    "\n",
    "# also 091221 P9HuP28 #13 S15-18369 A2_[5659,54652] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d01a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33df26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db751ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c05f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d9398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_cell_table))\n",
    "full_cell_table.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = full_cell_table.columns\n",
    "colnames = [re.sub(r'centroid-0', r'Cell_Y_Position', a) for a in colnames]\n",
    "colnames = [re.sub(r'centroid-1', r'Cell_X_Position', a) for a in colnames]\n",
    "\n",
    "colnames = ['ark_' + col for col in colnames]\n",
    "full_cell_table.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6753fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_cell_table))\n",
    "full_cell_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d2534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0488c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export entire file or specific rois if we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b40bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save extracted data as csv for downstream analysis\n",
    "# cell_table_size_normalized.to_csv(os.path.join(mask_dir, 'cell_table_size_normalized.csv'),\n",
    "#                                  index=False)\n",
    "# cell_table_arcsinh_transformed.to_csv(os.path.join(mask_dir, 'cell_table_arcsinh_transformed.csv'),\n",
    "#                                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa65e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_file(mask_file, component_file, marker_list, roi_idx):\n",
    "    '''\n",
    "    Arguments: mask_file as full filename of cell segmentation mask\n",
    "      img is greyscale all-channels image to use for intensity measurement\n",
    "      marker_list is ordered list of labels for each channel\n",
    "      idx is the iterator integer to keep cell ids unique\n",
    "    Returns: dataframe of cells with feature measurements  \n",
    "    '''\n",
    "\n",
    "    props = ['label', 'area', 'eccentricity', 'major_axis_length', 'minor_axis_length',\n",
    "             'perimeter', 'centroid', 'convex_area',\n",
    "             'equivalent_diameter']\n",
    "        \n",
    "    # open files\n",
    "    img_mask = io.imread(mask_file)\n",
    "    img_component = io.imread(component_file, plugin=\"tifffile\")\n",
    "    sample_name = os.path.basename(component_file).replace('_component_data.tif','')\n",
    "    sample_id = sample_name.split(\"_\")[0]\n",
    "    print(sample_id)\n",
    "    # this will be location of components_data.tif files \n",
    "    path = os.path.dirname(component_file)  \n",
    "    \n",
    "    print(sample_name)\n",
    "    print(path)\n",
    "    \n",
    "    # loop each channel for \n",
    "    for i in np.arange(len(marker_list)):\n",
    "        #print(\"Processing {} {}\".format(i, marker_list[i]))\n",
    "        img_i = img_component[i,:,:]\n",
    "        #print(img_i.shape)\n",
    "        \n",
    "        # accumulate dfs for each marker\n",
    "        current_props = pd.DataFrame(regionprops_table(img_mask, \n",
    "                                                       intensity_image=img_i,\n",
    "                                                       properties=['label', 'intensity_mean']))\n",
    "        \n",
    "        # colname like \"Entire Cell CD8 (Opal 780) Mean\"\n",
    "        current_props.columns = ['label', 'Entire Cell '+ marker_list[i]+' (' + opals[i] +') Mean']\n",
    "        current_props['point'] = str(roi_idx)\n",
    "        current_props['cell_id'] = current_props['point'].astype(str) +\"-\"+ current_props['label'].astype(str)\n",
    "        current_props.drop(['label', 'point'], axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "        if (i==0):\n",
    "            # merge generates duplicate columns; keep only one\n",
    "            current_props['Sample_ID'] = sample_id\n",
    "            current_props['Sample_Name'] = sample_name\n",
    "            current_props['path'] = path\n",
    "            df_merge = current_props\n",
    "        else:\n",
    "            df_merge = df_merge.merge(current_props, how='outer', left_on='cell_id', right_on='cell_id') \n",
    "    \n",
    "    # get the rest of the properties\n",
    "    props = pd.DataFrame(regionprops_table(img_mask, \n",
    "                          properties=props))   \n",
    "    props['point'] = str(roi_idx)\n",
    "    props['cell_id'] = props['point'].astype(str) +\"-\"+ props['label'].astype(str)\n",
    "\n",
    "    df_merge2 = df_merge.merge(props, how='outer', left_on='cell_id', right_on='cell_id') \n",
    "    \n",
    "    return df_merge2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df= get_stats_for_file(mask_file1, component_file1, channels, 0)\n",
    "\n",
    "# for FCS, keep only cell_id and Entire Cell measures\n",
    "# to keep only the Intensity measures\n",
    "colnames =  [col for col in df.columns if 'Entire Cell' in col]\n",
    "colnames = ['cell_id', 'Sample_ID'] + colnames \n",
    "print(colnames)\n",
    "\n",
    "# let's keep the numeric columns:\n",
    "df = df.select_dtypes(exclude='object')\n",
    "print(df.columns)\n",
    "\n",
    "# narrow down for now (FCS purposes)\n",
    "#df = df[colnames]\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_mantis(mask_file, component_file, marker_list):\n",
    "    '''\n",
    "    Arguments: mask_file as full filename of cell segmentation mask\n",
    "      img is greyscale all-channels image to use for intensity measurement\n",
    "      marker_list is ordered list of labels for each channel\n",
    "    Returns: dataframe of cells with feature measurements in mantis format \n",
    "        note: cell_id remains untouched so it will match the mask\n",
    "        and only numeric attributes allowed as features\n",
    "    '''\n",
    "\n",
    "    props = ['label', 'area', 'major_axis_length', 'minor_axis_length',\n",
    "             'perimeter', 'centroid']\n",
    "        \n",
    "    # open files\n",
    "    img_mask = io.imread(mask_file)\n",
    "    img_component = io.imread(component_file, plugin=\"tifffile\")\n",
    "    sample_name = os.path.basename(component_file).replace('_component_data.tif','')\n",
    "    sample_id = sample_name.split(\"_\")[0]\n",
    "    print(sample_id)\n",
    "    # this will be location of components files but orig would be of im3 files\n",
    "    path = os.path.dirname(component_file)  \n",
    "    \n",
    "    print(sample_name)\n",
    "    print(path)\n",
    "    \n",
    "    #print(img_mask.shape)\n",
    "    #print(img_component.shape)\n",
    "    # loop each channel for \n",
    "    for i in np.arange(len(marker_list)):\n",
    "        #print(\"Processing {} {}\".format(i, marker_list[i]))\n",
    "        img_i = img_component[i,:,:]\n",
    "        #print(img_i.shape)\n",
    "        \n",
    "        # accumulate dfs for each marker\n",
    "        current_props = pd.DataFrame(regionprops_table(img_mask, \n",
    "                                                       intensity_image=img_i,\n",
    "                                                       properties=['label', 'intensity_mean']))\n",
    "        \n",
    "        # colname like \"Entire Cell CD8 (Opal 780) Mean\"\n",
    "        current_props.columns = ['cell id', 'Entire Cell '+ marker_list[i]+' (' + opals[i] +') Mean']\n",
    "        \n",
    "        if (len(current_props) == 0):\n",
    "            continue\n",
    "            \n",
    "        if (i==0):\n",
    "            # merge generates duplicate columns\n",
    "            df_merge = current_props\n",
    "        else:\n",
    "            df_merge = df_merge.merge(current_props, how='outer', left_on='cell id', right_on='cell id') \n",
    "    \n",
    "    # get the rest of the properties\n",
    "    props = pd.DataFrame(regionprops_table(img_mask, \n",
    "                          properties=props))  \n",
    "    props.rename({'label':'cell id'}, axis=1, inplace=True)\n",
    "    df_merge2 = df_merge.merge(props, how='outer', left_on='cell id', right_on='cell id') \n",
    "    \n",
    "    return df_merge2\n",
    "\n",
    "\n",
    "\n",
    "mask_file1\n",
    "df= get_stats_for_mantis(mask_file1, component_file1, channels)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e40918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17752e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all files, group by sample\n",
    "isFirst=True\n",
    "for i, mask_file in enumerate(fname_masks):\n",
    "    \n",
    "    comp_file = mask_file.replace(\"MASK_\", \"\").replace(\"_rgb\", \"_component_data\") \\\n",
    "        .replace(masks_dir, components_dir)\n",
    "    comp_file\n",
    "    os.path.exists(comp_file)\n",
    "    \n",
    "    sample_nm = os.path.basename(mask_file).replace(\"MASK_\", \"\").replace(\"_rgb.tif\", \"\")\n",
    "    print(\"sample_nm {}\".format(sample_nm))\n",
    "\n",
    "    df= get_stats_for_file(mask_file, comp_file, channels, i)\n",
    "    \n",
    "    if (len(df) == 0):\n",
    "        continue\n",
    "    \n",
    "    # adding\n",
    "    df.rename({'cell_id': 'temp_cell_id'}, axis=\"columns\", inplace=True)\n",
    "    df.reset_index(inplace=True)  # already covered\n",
    "    #df.rename({'index': 'cell_id'}, axis=\"columns\", inplace=True)\n",
    "    # Lookup sample index from same table as ark data, for good matching key\n",
    "    sample_idx = df_samples[df_samples['sample_nm']==sample_nm].iloc[0,0]\n",
    "    #sample_idx.iloc[0,0]\n",
    "    df['sample_idx'] = sample_idx\n",
    "    df['unique_cell_id'] = df.apply(\n",
    "        lambda row: float(str(sample_idx) + \".\" + (\"0000\" + str(row.label))[-5:]), axis=1)\n",
    "        \n",
    "    if (isFirst): \n",
    "        df_full = df\n",
    "        isFirst=False\n",
    "    else:\n",
    "        df_full = pd.concat([df_full, df], axis=0) # same as append()\n",
    "        #df_full = df_full.append(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e310b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd419c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_full))\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d555d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary by sample\n",
    "df_full.groupby('Sample_Name')['unique_cell_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e5651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd10dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns\n",
    "df_full['label'] = np.arange(len(df_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e898b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full  # 170240 rows × 25 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f4ae0",
   "metadata": {},
   "source": [
    "### Combine df_full and df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_full.merge (full_cell_table, how=\"inner\", left_on=\"unique_cell_id\", right_on=\"ark_unique_cell_id\" )\n",
    "\n",
    "print(len(df_full), len(df_all))\n",
    "# 292632 370369 means some unique cell ids are not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb73d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(os.path.join(output_path, 'panel2_cell_features_all_samples.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv(os.path.join(output_path, 'panel2_mean-cell-measures.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.iloc[66,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e6055",
   "metadata": {},
   "source": [
    "## Extra Play Stuff (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5439578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop all for Mantis file structure\n",
    "\n",
    "mantis_dir = os.path.join(root_dir, 'Panel2/mantis-viewer')\n",
    "print('mantis dir exists: {}'.format(os.path.exists(mantis_dir)))\n",
    "\n",
    "\n",
    "for i, mask_file in enumerate(fname_masks[:1]):\n",
    "    \n",
    "    comp_file = mask_file.replace(\"MASK_\", \"\").replace(\"_rgb\", \"_component_data\") \\\n",
    "        .replace(masks_dir, components_dir)\n",
    "    comp_file\n",
    "    os.path.exists(comp_file)\n",
    "    \n",
    "    sample_name = os.path.basename(comp_file).replace('_component_data.tif','')\n",
    "    sample_id = sample_name.split(\"_\")[0]\n",
    "    print(sample_name)  \n",
    "\n",
    "\n",
    "    if not os.path.exists(os.path.join(mantis_dir, sample_name)):\n",
    "        print('create dir {}'.format(os.path.join(mantis_dir, sample_name)))\n",
    "        os.mkdir(os.path.join(mantis_dir, sample_name))\n",
    "        \n",
    "    mantis_dir_roi = os.path.join(mantis_dir, sample_name)    \n",
    "    shutil.copy(comp_file, mantis_dir_roi)\n",
    "    shutil.copy(mask_file, mantis_dir_roi)\n",
    "    \n",
    "    df_roi = get_stats_for_mantis(mask_file, comp_file, channels)\n",
    "    print(df_roi.columns)\n",
    "    df_roi.to_csv(os.path.join(mantis_dir_roi, 'cell_features.csv'), header=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced93204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce7e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437cb642",
   "metadata": {},
   "source": [
    "## Loop all for FCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chop up df_full by sample to create FCS files\n",
    "\n",
    "# for each sample id, select from df_full\n",
    "sample_id_list = pd.unique(df_full['Sample_ID'])\n",
    "print(len(sample_id_list),sample_id_list[:2])\n",
    "\n",
    "for i, sample_id in enumerate(sample_id_list):\n",
    "    \n",
    "    # get our sample (multiple rois)\n",
    "    sample_df = df_full[df_full['Sample_ID']==sample_id]\n",
    "    sample_df = sample_df.select_dtypes(exclude='object')\n",
    "    \n",
    "    sample_from_df = fk.Sample(sample_df, sample_id=sample_id)\n",
    "    # e.g. 091221 P9HuP28 #14 S15-014984 A4\n",
    "    fcs_filename = sample_id + '.fcs'\n",
    "    sample_from_df.export(os.path.join(root_dir, fcs_path,fcs_filename),\n",
    "                     source='raw')\n",
    "    print('Export {} rows to {}'.format(sample_from_df.event_count, fcs_filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81612e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0c6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full.columns)\n",
    "# to csv to match Consolidated_data.txt\n",
    "\n",
    "df_full.to_csv(os.path.join(root_dir, 'Panel2','cellpose_metrics.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some columns we need for phenoptr:\n",
    "\n",
    "df_full[\"Tissue Category\"] = \"Total\"\n",
    "df_full[\"Region ID\"] = 0\n",
    "df_full['path'] = '\\\\data.ucdenver.pvt\\dept\\SOM\\HIMSR\\Archive\\All\\Polaris\\Data\\VectraPolaris \\\n",
    "                    \\Woods 2021\\091021 P9HuP27 #01 S18-20937 F4\\Scan1\\MSI'\n",
    "\n",
    "\n",
    "\n",
    "#Sample_Name = '091021 P9HuP27 #01 S18-20937 F4_[10177,41847].im3'\n",
    "#Lab ID\n",
    "Slide_ID  = '091021 P9HuP27 #01 S18-20937 F4'\n",
    "\n",
    "# For Consolidated data format, we'll need Phenotypes e.g. CD8 as CD8+ or CD8- from gating output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list comprehension to make string changes e.g. cell_id to fil\n",
    "colnames = df_full.columns\n",
    "colnames = [re.sub(r'centroid-0', r'Cell Y Position', a) for a in colnames]\n",
    "colnames = [re.sub(r'centroid-1', r'Cell X Position', a) for a in colnames]\n",
    "\n",
    "# columns I want include\n",
    "# tag\n",
    "# Sample Name \n",
    "# e.g. 'Entire Cell CD3 (Opal 480) Mean'\n",
    "# Tissue Category = 'Total'\n",
    "# Region ID = 1\n",
    "\n",
    "#df_full.columns = colnames\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f137d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure cell labels remain unique\n",
    "\n",
    "# list comprehension to make string changes e.g. cell_id to fil\n",
    "colnames = df_full.columns\n",
    "colnames = [re.sub(r'cell_id', r'fil', a) for a in colnames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d11995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.drop('cell_id', axis=1, inplace=True)\n",
    "df.drop('Sample_ID', axis=1, inplace=True) # 091221 P9HuP28 #14 S15-014984 A4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.reset_index()\n",
    "df.rename(columns={'label': 'fil'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2603df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to FCS with flowkit\n",
    "# https://flowkit.readthedocs.io/en/latest/notebooks/flowkit-tutorial-part01-sample-class.html\n",
    "\n",
    "\n",
    "sample_from_df = fk.Sample(df, sample_id='091221 P9HuP28 #14 S15-014984 A4')\n",
    "sample_from_df\n",
    "\n",
    "# sample1 = fk.Sample(\n",
    "#     fcs_path_or_data = df_full,\n",
    "#     id=None,\n",
    "#     channel_labels=None,\n",
    "#     compensation=None,\n",
    "#     null_channel_list=None,\n",
    "#     ignore_offset_error=False,\n",
    "#     ignore_offset_discrepancy=False,\n",
    "#     use_header_offsets=False,\n",
    "#     cache_original_events=False\n",
    "#     #subsample=10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f30cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: do we load individual FCS files for each slide? (aka Sample), (up to 15 slides per patient)\n",
    "#.  or treat as concatenated file with additional attributes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc510e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_df.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd897c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_df.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40087a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_df.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_df.pnn_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_df.pns_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd94b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sample_from_df.plot_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8099af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram\n",
    "p = sample_from_df.plot_histogram('Entire Cell CD3 (Opal 480) Mean', source='raw')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, plot_contour uses sub-sampled events for performance\n",
    "x_min = y_min = 0\n",
    "x_max = y_max = 250\n",
    "\n",
    "f = sample_from_df.plot_contour('Entire Cell CD4 (Opal 540) Mean', \n",
    "                                'Entire Cell CD8 (Opal 780) Mean', \n",
    "                                source='raw')\n",
    "                                #x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max)\n",
    "print(type(f))\n",
    "plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28428e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbff163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a matplotlib histogram\n",
    "plt.hist(df[\"Entire Cell CD3 (Opal 480) Mean\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sample_from_df.plot_scatter(\n",
    "    'Entire Cell CD4 (Opal 540) Mean', \n",
    "    'Entire Cell CD8 (Opal 780) Mean', \n",
    "    source='raw',\n",
    "    #y_min=0., y_max=130, x_min=0., x_max=280, \n",
    "    color_density=True\n",
    ")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "xform = fk.transforms.LogicleTransform('my_logicle', param_t=1024, param_w=0.5, param_m=4.5, param_a=0)\n",
    "sample_from_df.apply_transform(xform)\n",
    "# source is 'raw' so not too useful for visualization\n",
    "p = sample_from_df.plot_scatter('Entire Cell CD4 (Opal 540) Mean', \n",
    "                        'Entire Cell CD8 (Opal 780) Mean', \n",
    "                        source='raw')\n",
    "show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125650d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 091221 P9HuP28 #14 S15-014984 A4\n",
    "sample_from_df.export(os.path.join(root_dir, fcs_path,'091221 P9HuP28 #14 S15-014984 A4_test1.fcs'),\n",
    "                     source='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77faef54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a62de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1c055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
